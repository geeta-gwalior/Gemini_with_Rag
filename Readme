RAG Application with Gemini AI
This project demonstrates how to build a simple Retrieval-Augmented Generation (RAG) pipeline using Google Gemini AI and LangChain. The system loads a PDF, splits it into chunks, stores embeddings in a vector database (Chroma), retrieves relevant documents, and generates concise answers using a question-answering chain.

Steps:
Load PDF: Use PyPDFLoader to load and process a PDF.
Split Text: Break the document into smaller chunks using RecursiveCharacterTextSplitter.
Embeddings: Generate text embeddings with Gemini AI.
Vector Store: Store the embeddings in Chroma (alternatives: Pinecone, FAISS, Weaviate).
Document Retrieval: Retrieve relevant documents based on a user query.
Question-Answer Chain: Use Gemini AI to generate answers using retrieved documents.
https://medium.com/p/24636dd21f5b/edit
